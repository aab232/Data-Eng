{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a7f1cb2-b466-4162-8ff9-956061753007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector-python\n",
      "  Downloading mysql_connector_python-9.2.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (6.0 kB)\n",
      "Downloading mysql_connector_python-9.2.0-cp312-cp312-macosx_14_0_arm64.whl (15.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mysql-connector-python\n",
      "Successfully installed mysql-connector-python-9.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7e27ecf-fd6f-4456-8bce-27ff4d16f0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database and tables are ready!\n",
      "                                               Author  \\\n",
      "0   Book 3 of 3: The Innovators of AI and Data Series   \n",
      "1                                      James Densmore   \n",
      "2                             Cole Nussbaumer Knaflic   \n",
      "3                                        Gareth Eagar   \n",
      "4                                        Gareth Eagar   \n",
      "5                                      Kedeisha Bryan   \n",
      "6                                      Kedeisha Bryan   \n",
      "7                                       Paul Houghton   \n",
      "8                           Simon Aubury, Ned Letcher   \n",
      "9                                       Paul Crickard   \n",
      "10                                      Roberto Zagni   \n",
      "11              Richard J. Schiller, David Larochelle   \n",
      "12                                      Pulkit Chadha   \n",
      "13                                      Vlad Riscutia   \n",
      "14                             Joe Reis, Matt Housley   \n",
      "\n",
      "                                                Title  Rating  Price  \n",
      "0   Data Engineering Excellence: Architecting Resi...     4.7    0.0  \n",
      "1   Data Pipelines Pocket Reference: Moving and Pr...     4.6   17.0  \n",
      "2   Storytelling with Data: A Data Visualization G...     4.6   21.0  \n",
      "3   Data Engineering with AWS: Acquire the skills ...     4.3   24.0  \n",
      "4   Data Engineering with AWS: Acquire the skills ...     4.3   24.0  \n",
      "5   Cracking the Data Engineering Interview: Land ...     4.0   26.0  \n",
      "6   Cracking the Data Engineering Interview: Land ...     4.0   26.0  \n",
      "7   Data Engineering with Alteryx: Helping data en...     4.3   31.0  \n",
      "8   Getting Started with DuckDB: A practical guide...     3.4   35.0  \n",
      "9   Data Engineering with Python: Work with massiv...     4.1   37.0  \n",
      "10  Data Engineering with dbt: A practical guide t...     4.7   37.0  \n",
      "11  Data Engineering Best Practices: Architect rob...     5.0   39.0  \n",
      "12  Data Engineering with Databricks Cookbook: Bui...     4.4   39.0  \n",
      "13                          Data Engineering on Azure     4.5   43.0  \n",
      "14  Fundamentals of Data Engineering: Plan and Bui...     4.7   43.0  \n",
      "Data successfully stored in MySQL and sorted data saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import csv\n",
    "import mysql.connector\n",
    "\n",
    "# Amazon URL for Data Engineering Books\n",
    "URL = \"https://www.amazon.com/s?k=data+engineering+books\"\n",
    "\n",
    "# User-Agent list to avoid detection\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\"\n",
    "]\n",
    "\n",
    "HEADERS = {\"User-Agent\": random.choice(USER_AGENTS), \"Accept-Language\": \"en-US,en;q=0.5\"}\n",
    "\n",
    "# Fetch search results\n",
    "response = requests.get(URL, headers=HEADERS)\n",
    "titles, authors, ratings, prices = [], [], [], []\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    books = soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\"})\n",
    "    \n",
    "    for book in books[:25]:\n",
    "        title_tag = book.find(\"h2\", class_=\"a-size-base-plus a-spacing-none a-color-base a-text-normal\")\n",
    "        title = title_tag.text.strip() if title_tag else None\n",
    "\n",
    "        author_tag = book.find(\"div\", class_=\"a-row a-size-base a-color-secondary\")\n",
    "        author_links = author_tag.find_all(\"a\") if author_tag else []\n",
    "        author = \", \".join([a.text.strip() for a in author_links]) if author_links else None\n",
    "\n",
    "        rating_tag = book.find(\"span\", class_=\"a-icon-alt\")\n",
    "        rating = rating_tag.text.strip().split()[0] if rating_tag else None\n",
    "\n",
    "        price_tag = book.find(\"span\", class_=\"a-price-whole\")\n",
    "        price = price_tag.text.strip() if price_tag else None\n",
    "\n",
    "        titles.append(title)\n",
    "        authors.append(author)\n",
    "        ratings.append(rating)\n",
    "        prices.append(price)\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Title\": titles,\n",
    "        \"Author\": authors,\n",
    "        \"Rating\": ratings,\n",
    "        \"Price\": prices\n",
    "    })\n",
    "    \n",
    "    df.to_csv(\"amazon_books.csv\", index=False, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "    # **MySQL Database Connection - Ensuring Database Exists**\n",
    "    conn = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"jasonrules12\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # **Create Database If Not Exists**\n",
    "    cursor.execute(\"CREATE DATABASE IF NOT EXISTS bookstore_db\")\n",
    "    cursor.execute(\"USE bookstore_db\")\n",
    "\n",
    "    # **Creating Tables Based on Given Schema**\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS authors (\n",
    "            AuthorID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            AuthorName VARCHAR(255) UNIQUE\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS books (\n",
    "            BookID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            Title VARCHAR(255) UNIQUE\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS bookstore (\n",
    "            StoreID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            BookID INT,\n",
    "            AuthorID INT,\n",
    "            Price FLOAT,\n",
    "            Rating FLOAT,\n",
    "            FOREIGN KEY (BookID) REFERENCES books(BookID),\n",
    "            FOREIGN KEY (AuthorID) REFERENCES authors(AuthorID)\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    print(\"Database and tables are ready!\")\n",
    "\n",
    "    # Insert Data into MySQL Tables\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notnull(row['Title']) and pd.notnull(row['Author']) and pd.notnull(row['Rating']) and pd.notnull(row['Price']):\n",
    "            # Insert Author\n",
    "            cursor.execute(\"INSERT IGNORE INTO authors (AuthorName) VALUES (%s)\", (row['Author'],))\n",
    "            conn.commit()\n",
    "\n",
    "            # Retrieve AuthorID\n",
    "            cursor.execute(\"SELECT AuthorID FROM authors WHERE AuthorName = %s\", (row['Author'],))\n",
    "            author_id = cursor.fetchone()[0]\n",
    "\n",
    "            # Insert Book\n",
    "            cursor.execute(\"INSERT IGNORE INTO books (Title) VALUES (%s)\", (row['Title'],))\n",
    "            conn.commit()\n",
    "\n",
    "            # Retrieve BookID\n",
    "            cursor.execute(\"SELECT BookID FROM books WHERE Title = %s\", (row['Title'],))\n",
    "            book_id = cursor.fetchone()[0]\n",
    "\n",
    "            # Insert into bookstore (Ensuring Unique Entries)\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO bookstore (BookID, AuthorID, Price, Rating)\n",
    "                VALUES (%s, %s, %s, %s)\n",
    "            \"\"\", (book_id, author_id, row['Price'], row['Rating']))\n",
    "            conn.commit()\n",
    "\n",
    "    # Retrieve and Sort Books\n",
    "    query = \"\"\"\n",
    "        SELECT authors.AuthorName, books.Title, bookstore.Rating, bookstore.Price\n",
    "        FROM bookstore\n",
    "        JOIN books ON bookstore.BookID = books.BookID\n",
    "        JOIN authors ON bookstore.AuthorID = authors.AuthorID\n",
    "        WHERE books.Title IS NOT NULL\n",
    "        ORDER BY bookstore.Price ASC\n",
    "        LIMIT 15;\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(query)\n",
    "    results = cursor.fetchall()\n",
    "    df_result = pd.DataFrame(results, columns=[\"Author\", \"Title\", \"Rating\", \"Price\"])\n",
    "    print(df_result)\n",
    "    df_result.to_csv(\"sorted_books.csv\", index=False)\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"Data successfully stored in MySQL and sorted data saved to CSV.\")\n",
    "else:\n",
    "    print(\"Failed to retrieve webpage. Amazon may have blocked the request.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca7b68-6846-49ba-8516-a2d80c49beee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
