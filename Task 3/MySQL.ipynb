{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7729291b-0787-4a5e-b765-32bb4e95aeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Database and tables are ready!\n",
      "âœ… Data successfully inserted into MySQL!\n",
      "\n",
      "ðŸ“Œ Filtered Books from MySQL:\n",
      "\n",
      "+----+----------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+---------+\n",
      "|    | Author                                                                           | Title                                                                                                                                                                              |   Rating |   Price |\n",
      "|----+----------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+---------|\n",
      "|  0 | Book 3 of 3: The Innovators of AI and Data Series                                | \"Data Engineering Excellence: Architecting Resilient Systems from Scratch to Scale (The Innovators of AI and Data Series Book 3)\"                                                  |      4.7 |       0 |\n",
      "|  1 | Book 1 of 4: Future-Proof Tech Skills: Including AI, Python, SQL, Linux And More | \"Python Data Engineering Resources: Forge Your Path to Success in Data Engineering, Machine Learning and AI (Future-Proof Tech Skills: Including AI, Python, SQL, Linux And More)\" |      4.9 |       9 |\n",
      "|  2 | James Densmore                                                                   | \"Data Pipelines Pocket Reference: Moving and Processing Data for Analytics\"                                                                                                        |      4.6 |      17 |\n",
      "|  3 | Cole Nussbaumer Knaflic                                                          | \"Storytelling with Data: A Data Visualization Guide for Business Professionals\"                                                                                                    |      4.6 |      21 |\n",
      "|  4 | Gareth Eagar                                                                     | \"Data Engineering with AWS: Acquire the skills to design and build AWS-based data transformation pipelines like a pro\"                                                             |      4.3 |      24 |\n",
      "|  5 | Gareth Eagar                                                                     | \"Data Engineering with AWS: Acquire the skills to design and build AWS-based data transformation pipelines like a pro\"                                                             |      4.3 |      24 |\n",
      "|  6 | Kedeisha Bryan                                                                   | \"Cracking the Data Engineering Interview: Land your dream job with the help of resume-building tips, over 100 mock questions, and a unique portfolio\"                              |      4   |      26 |\n",
      "|  7 | Kedeisha Bryan                                                                   | \"Cracking the Data Engineering Interview: Land your dream job with the help of resume-building tips, over 100 mock questions, and a unique portfolio\"                              |      4   |      26 |\n",
      "|  8 | Paul Houghton                                                                    | \"Data Engineering with Alteryx: Helping data engineers apply DataOps practices with Alteryx\"                                                                                       |      4.3 |      31 |\n",
      "|  9 | Paul Crickard                                                                    | \"Data Engineering with Python: Work with massive datasets to design data models and automate data pipelines using Python\"                                                          |      4.1 |      37 |\n",
      "| 10 | Roberto Zagni                                                                    | \"Data Engineering with dbt: A practical guide to building a cloud-based, pragmatic, and dependable data platform with SQL\"                                                         |      4.7 |      37 |\n",
      "| 11 | Richard J. Schiller, David Larochelle                                            | \"Data Engineering Best Practices: Architect robust and cost-effective data solutions in the cloud era\"                                                                             |      5   |      39 |\n",
      "| 12 | Pulkit Chadha                                                                    | \"Data Engineering with Databricks Cookbook: Build effective data and AI solutions using Apache Spark, Databricks, and Delta Lake\"                                                  |      4.4 |      39 |\n",
      "| 13 | Vlad Riscutia                                                                    | \"Data Engineering on Azure\"                                                                                                                                                        |      4.5 |      43 |\n",
      "| 14 | Joe Reis, Matt Housley                                                           | \"Fundamentals of Data Engineering: Plan and Build Robust Data Systems\"                                                                                                             |      4.7 |      43 |\n",
      "+----+----------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+---------+\n",
      "ðŸ“Œ MySQL Query Execution Time: 0.00053 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from tabulate import tabulate  # Import tabulate for a better table format\n",
    "\n",
    "# Connect to MySQL\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Aliza.123\",  # Replace with your actual MySQL password\n",
    "    database=\"bookstore_db\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Ensure tables exist\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS authors (\n",
    "        AuthorID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        AuthorName VARCHAR(255) UNIQUE\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS books (\n",
    "        BookID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        Title VARCHAR(255) UNIQUE\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS bookstore (\n",
    "        StoreID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        BookID INT,\n",
    "        AuthorID INT,\n",
    "        Price DECIMAL(10,2),\n",
    "        Rating FLOAT,\n",
    "        FOREIGN KEY (BookID) REFERENCES books(BookID),\n",
    "        FOREIGN KEY (AuthorID) REFERENCES authors(AuthorID)\n",
    "    )\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "print(\"âœ… Database and tables are ready!\")\n",
    "\n",
    "# Load book data from CSV\n",
    "df = pd.read_csv(\"amazon_data_engineering_books.csv\")\n",
    "\n",
    "# Insert Data into MySQL Tables\n",
    "for index, row in df.iterrows():\n",
    "    if pd.notnull(row['Title']) and pd.notnull(row['Author']) and pd.notnull(row['Rating']) and pd.notnull(row['Price']):\n",
    "        # Insert Author\n",
    "        cursor.execute(\"INSERT IGNORE INTO authors (AuthorName) VALUES (%s)\", (row['Author'],))\n",
    "        conn.commit()\n",
    "\n",
    "        # Retrieve AuthorID\n",
    "        cursor.execute(\"SELECT AuthorID FROM authors WHERE AuthorName = %s\", (row['Author'],))\n",
    "        author_id = cursor.fetchone()[0]\n",
    "\n",
    "        # Insert Book\n",
    "        cursor.execute(\"INSERT IGNORE INTO books (Title) VALUES (%s)\", (row['Title'],))\n",
    "        conn.commit()\n",
    "\n",
    "        # Retrieve BookID\n",
    "        cursor.execute(\"SELECT BookID FROM books WHERE Title = %s\", (row['Title'],))\n",
    "        book_id = cursor.fetchone()[0]\n",
    "\n",
    "        # Insert into bookstore (Avoid duplicates)\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT IGNORE INTO bookstore (BookID, AuthorID, Price, Rating)\n",
    "            VALUES (%s, %s, %s, %s)\n",
    "        \"\"\", (book_id, author_id, row['Price'], row['Rating']))\n",
    "        conn.commit()\n",
    "\n",
    "print(\"âœ… Data successfully inserted into MySQL!\")\n",
    "\n",
    "# SQL query to fetch books published after 2015 and price below $50\n",
    "sql_query = \"\"\"\n",
    "    SELECT authors.AuthorName, books.Title, bookstore.Rating, bookstore.Price\n",
    "    FROM bookstore\n",
    "    JOIN books ON bookstore.BookID = books.BookID\n",
    "    JOIN authors ON bookstore.AuthorID = authors.AuthorID\n",
    "    WHERE bookstore.Price < 50\n",
    "    ORDER BY bookstore.Price ASC\n",
    "    LIMIT 15;\n",
    "\"\"\"\n",
    "\n",
    "# Measure MySQL query execution time\n",
    "start_time = time.time()\n",
    "cursor.execute(sql_query)\n",
    "sql_results = cursor.fetchall()\n",
    "sql_time = time.time() - start_time  # âœ… Measures query speed\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df_sql = pd.DataFrame(sql_results, columns=[\"Author\", \"Title\", \"Rating\", \"Price\"])\n",
    "\n",
    "# Display results\n",
    "print(\"\\nðŸ“Œ Filtered Books from MySQL:\\n\")\n",
    "print(tabulate(df_sql, headers=\"keys\", tablefmt=\"psql\"))  # Formats output as a clean table\n",
    "\n",
    "# Print execution time\n",
    "print(f\"ðŸ“Œ MySQL Query Execution Time: {sql_time:.5f} seconds\")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e364e8-3b9e-4f8e-8806-664896b2151b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
