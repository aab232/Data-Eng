{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fdc3864-c3c2-4a81-ad49-6c28f7947fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.12/site-packages (5.2.1)\n",
      "Collecting fake_useragent\n",
      "  Downloading fake_useragent-2.0.3-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading fake_useragent-2.0.3-py3-none-any.whl (201 kB)\n",
      "Installing collected packages: fake_useragent\n",
      "Successfully installed fake_useragent-2.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4 requests pandas lxml fake_useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0bc251e-7ef0-4875-abe0-38a97640a694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraped Data:\n",
      "\n",
      "                                                                                                                                                                                                 Title                                            Author  Publication Date Rating Price\n",
      "                                                                                                                                             \"Hands-On Data Engineering with R, Python and PostgreSQL\"                                   Michel Ballings December 14, 2024   None 69.00\n",
      "                                                                                \"Data Engineering with AWS: Acquire the skills to design and build AWS-based data transformation pipelines like a pro\"                                      Gareth Eagar  October 31, 2023    4.3 24.00\n",
      "                                                 \"Cracking the Data Engineering Interview: Land your dream job with the help of resume-building tips, over 100 mock questions, and a unique portfolio\"                                    Kedeisha Bryan  November 7, 2023    4.0 26.00\n",
      "                                                                                                          \"Data Engineering with Alteryx: Helping data engineers apply DataOps practices with Alteryx\"                                     Paul Houghton     June 30, 2022    4.3 31.00\n",
      "                                                                                                                                \"Fundamentals of Data Engineering: Plan and Build Robust Data Systems\"                            Joe Reis, Matt Housley     July 26, 2022    4.7 43.00\n",
      "                                                                                            \"Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems\"                                  Martin Kleppmann     April 2, 2017    4.8 40.00\n",
      "                                                                                                     \"Data Engineering Design Patterns: Recipes for Solving the Most Common Data Engineering Problems\"                                              None      June 3, 2025   None 79.00\n",
      "                                                                                \"Data Engineering with AWS: Acquire the skills to design and build AWS-based data transformation pipelines like a pro\"                                      Gareth Eagar  October 31, 2023    4.3 24.00\n",
      "                                                                                                                                        \"AI Engineering: Building Applications with Foundation Models\"                                        Chip Huyen   January 7, 2025    4.6 59.00\n",
      "                                                                                                                         \"Financial Data Engineering: Design and Build Data-Driven Financial Products\"                                    Tamer Khraisha November 12, 2024    5.0 59.00\n",
      "                                                                                                                           \"Data Pipelines Pocket Reference: Moving and Processing Data for Analytics\"                                    James Densmore    March 16, 2021    4.6 17.00\n",
      "                                                                                                \"Data Engineering Best Practices: Architect robust and cost-effective data solutions in the cloud era\"             Richard J. Schiller, David Larochelle  October 11, 2024    5.0 39.00\n",
      "                                                  \"The Data Engineering Handbook: We are Data Engineers, we make things happen, we pull rabbits out of hats, and transform raw, noisy data into gold.\"                                              None  October 17, 2024    5.0  9.00\n",
      "                                                 \"Cracking the Data Engineering Interview: Land your dream job with the help of resume-building tips, over 100 mock questions, and a unique portfolio\"                                    Kedeisha Bryan  November 7, 2023    4.0 26.00\n",
      "                                                                                           \"Ace the Data Science Interview: 201 Real Interview Questions Asked By FAANG, Tech Startups, & Wall Street\"                             Nick Singh, Kevin Huo   August 16, 2021    4.5 42.00\n",
      "                                                                     \"Data Engineering with Databricks Cookbook: Build effective data and AI solutions using Apache Spark, Databricks, and Delta Lake\"                                     Pulkit Chadha      May 31, 2024    4.4 39.00\n",
      "                                                                          \"Data Engineering with AWS Cookbook: A recipe-based approach to help you tackle data engineering problems with AWS services\"         Trâm Ngọc Phạm, Gonzalo Herreros González November 29, 2024    5.0 49.00\n",
      "                                                                                                                                                                          \"Snowflake Data Engineering\"                                        Maja Ferle  January 28, 2025    4.7 49.00\n",
      "\"Kafka Data Engineer (KDE) Handbook - Kafka Development & Engineering Guide: Advanced Kafka Skills for Data Engineers (KDE): Custom Topic Management, ... Streaming, Real-time Analytics (KAFKA 2025)\"                                      Tony CL Chan              2025   None 38.00\n",
      "                                                                   \"Getting Started with DuckDB: A practical guide for accelerating your data science, data analytics, and data engineering workflows\"                         Simon Aubury, Ned Letcher     June 24, 2024    3.4 35.00\n",
      "                                                                     \"Data Engineering Excellence: Architecting Resilient Systems from Scratch to Scale (The Innovators of AI and Data Series Book 3)\" Book 3 of 3: The Innovators of AI and Data Series February 24, 2025    4.6  0.00\n",
      "                                                                                                                                                                          \"Snowflake Data Engineering\"                                        Maja Ferle  January 28, 2025    4.7 49.00\n",
      "                                                                            \"Data Engineering with dbt: A practical guide to building a cloud-based, pragmatic, and dependable data platform with SQL\"                                     Roberto Zagni     June 30, 2023    4.7 37.00\n",
      "                                                                             \"Data Engineering with Python: Work with massive datasets to design data models and automate data pipelines using Python\"                                     Paul Crickard  October 23, 2020    4.1 37.00\n",
      "                                                                                                    \"Managing Data as a Product: Design and build data-product-centered socio-technical architectures\"                                      Andrea Gioia November 29, 2024    4.4 44.00\n",
      "\n",
      "Data successfully saved to 'amazon_data_engineering_books.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests # sends http requests\n",
    "from bs4 import BeautifulSoup # used  for parsing html data\n",
    "import pandas as pd # handles data frames and data manipulation\n",
    "import time # used for sleep functions to delay scraping requests\n",
    "import random # generates random delays between requests\n",
    "import re # used for pattern matching\n",
    "import csv # writes data to .csv file\n",
    "\n",
    "# AMAZON URL FOR DATA ENGINEERING BOOKS SEARCH RESULTS\n",
    "URL = \"https://www.amazon.com/s?k=data+engineering+books\"\n",
    "\n",
    "# USER-AGENT LIST TO AVOID DETECTION BY AMAZON\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\"\n",
    "]\n",
    "\n",
    "# HEADERS TO MIMIC A REAL BROWSER REQUEST FOR SCRAPING\n",
    "HEADERS = {\n",
    "    \"User-Agent\": random.choice(USER_AGENTS),  # randomly choose a user-agent to avoid detection\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\"  # define acceptable languages in the request\n",
    "}\n",
    "\n",
    "# FUNCTION TO GET PUBLICATION DATE FROM BOOK'S PRODUCT PAGE\n",
    "def get_publication_date_from_product_page(book_url):\n",
    "    \"\"\"Fetch the publication date from a book's product page.\"\"\"\n",
    "    try:\n",
    "        # SEND REQUEST TO BOOK'S PRODUCT PAGE\n",
    "        product_response = requests.get(book_url, headers=HEADERS)\n",
    "        \n",
    "        # CHECK IF THE PAGE LOADS SUCCESSFULLY\n",
    "        if product_response.status_code == 200:\n",
    "            product_soup = BeautifulSoup(product_response.text, \"html.parser\")  # parses html response\n",
    "            # POSSIBLE LOCATIONS TO LOOK FOR PUBLICATION DATE\n",
    "            possible_locations = [\n",
    "                \"#detailBullets_feature_div\", \n",
    "                \"#productDetailsTable\", \n",
    "                \"#prodDetails\"\n",
    "            ]\n",
    "            for location in possible_locations:  # checks all locations\n",
    "                details = product_soup.select_one(location)  # gets the element containing details\n",
    "                if details:\n",
    "                    detail_text = details.get_text(strip=True)  # cleans up the text\n",
    "                    # SEARCH FOR A FULL DATE PATTERN\n",
    "                    date_match = re.search(r\"(January|February|March|April|May|June|July|August|September|October|November|December) \\d{1,2}, \\d{4}\", detail_text)\n",
    "                    if date_match:\n",
    "                        return date_match.group()  # returns the found date\n",
    "\n",
    "            # IF NO FULL DATE FOUND, SEARCH FOR A YEAR IN THE TEXT\n",
    "            year_match = re.search(r\"(19|20)\\d{2}\", product_soup.text)\n",
    "            if year_match:\n",
    "                return year_match.group()  # returns the year\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching product page: {e}\")  # prints error if exception error occurs\n",
    "    return None  # returns none if no date is found\n",
    "\n",
    "# FETCH MAIN SEARCH RESULTS PAGE FROM AMAZON\n",
    "response = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "# CHECK IF PAGE RETRIEVAL WAS SUCCESSFUL\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")  # parses html of main page\n",
    "    titles, authors, pub_dates, ratings, prices = [], [], [], [], []  # lists to store scraped data\n",
    "    books = soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\"})  # finds all book entries\n",
    "\n",
    "    # LOOP THROUGH FIRST 25 BOOKS\n",
    "    for book in books[:25]:\n",
    "        title_tag = book.find(\"h2\", class_=\"a-size-base-plus a-spacing-none a-color-base a-text-normal\")  # finds title\n",
    "        title = f'\"{title_tag.text.strip()}\"' if title_tag else None  # encloses title in quotes\n",
    "\n",
    "        # EXTRACT AUTHOR INFORMATION\n",
    "        author_tag = book.find(\"div\", class_=\"a-row a-size-base a-color-secondary\")\n",
    "        if author_tag:\n",
    "            author_links = author_tag.find_all(\"a\")\n",
    "            author = \", \".join([a.text.strip() for a in author_links]) if author_links else None  # combines author names\n",
    "        else:\n",
    "            author = None\n",
    "\n",
    "        # EXTRACT PUBLICATION DATE\n",
    "        pub_date = None\n",
    "        date_spans = book.find_all(\"span\", class_=\"a-size-base a-color-secondary\")  # finds all date spans\n",
    "        for span in date_spans:\n",
    "            span_text = span.get_text(strip=True)\n",
    "            # SEARCH FOR A FULL DATE FORMAT\n",
    "            date_match = re.search(r\"(January|February|March|April|May|June|July|August|September|October|November|December) \\d{1,2}, \\d{4}\", span_text)\n",
    "            if date_match:\n",
    "                pub_date = date_match.group()  # sets publication date\n",
    "                break\n",
    "        \n",
    "        # IF NO FULL DATE, SEARCH FOR A YEAR ONLY\n",
    "        if pub_date is None:\n",
    "            year_match = re.search(r\"(19|20)\\d{2}\", book.text)\n",
    "            if year_match:\n",
    "                pub_date = year_match.group()  # sets publication year\n",
    "\n",
    "        # EXTRACT RATING\n",
    "        rating_tag = book.find(\"span\", class_=\"a-icon-alt\")\n",
    "        rating = rating_tag.text.strip().split()[0] if rating_tag else None  # extracts rating value\n",
    "\n",
    "        # EXTRACT PRICE\n",
    "        price_tag = book.find(\"span\", class_=\"a-price-whole\")\n",
    "        if not price_tag:\n",
    "            price_tag = book.find(\"span\", class_=\"a-offscreen\")\n",
    "        \n",
    "        if price_tag:\n",
    "            price = price_tag.text.strip()\n",
    "            price = f\"{float(price):.2f}\" if price else None  # ensures two decimal places for price\n",
    "        else:\n",
    "            price = None\n",
    "\n",
    "        # EXTRACT BOOK URL FOR FURTHER DETAILS\n",
    "        book_url_tag = book.find(\"a\", class_=\"a-link-normal s-no-outline\")\n",
    "        book_url = \"https://www.amazon.com\" + book_url_tag[\"href\"] if book_url_tag else None  # creates full url\n",
    "\n",
    "        # FETCH PUBLICATION DATE FROM PRODUCT PAGE IF MISSING\n",
    "        if pub_date is None and book_url:\n",
    "            pub_date = get_publication_date_from_product_page(book_url)\n",
    "\n",
    "        # APPEND EXTRACTED DATA TO LISTS\n",
    "        titles.append(title)\n",
    "        authors.append(author)\n",
    "        pub_dates.append(pub_date)\n",
    "        ratings.append(rating)\n",
    "        prices.append(price)\n",
    "\n",
    "        # RESPECT AMAZON SCRAPING GUIDELINES BY ADDING RANDOM DELAY\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "\n",
    "    # CREATE PANDAS DATAFRAME WITH SCRAPED DATA\n",
    "    df = pd.DataFrame({\n",
    "        \"Title\": titles,\n",
    "        \"Author\": authors,\n",
    "        \"Publication Date\": pub_dates,\n",
    "        \"Rating\": ratings,\n",
    "        \"Price\": prices\n",
    "    })\n",
    "\n",
    "    # SAVE DATA TO CSV WITH PROPER QUOTING\n",
    "    df.to_csv(\"amazon_data_engineering_books.csv\", index=False, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "    # DISPLAY THE SCRAPED DATA\n",
    "    print(\"\\nScraped Data:\\n\")\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"\\nData successfully saved to 'amazon_data_engineering_books.csv'.\")\n",
    "else:\n",
    "    print(\"Failed to retrieve webpage. Amazon may have blocked the request.\")  # error handling failure in retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b720b68-ab14-4e79-8491-da348df6a621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
